{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5453e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b647e8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "class cfg:\n",
    "    user_token = \"<usr>\"\n",
    "    bot_token = \"<sys>\"\n",
    "    bos_token = '<s>'\n",
    "    eos_token = '</s>'\n",
    "    mask_token = '<mask>'\n",
    "    pad_token = '<pad>'\n",
    "    unk_token = '<unk>'\n",
    "    max_len = 256\n",
    "    max_turns = 6\n",
    "    pre_epochs = 0\n",
    "    epochs = 5\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    learning_rate = 1e-4\n",
    "    model_name = \"skt/kogpt2-base-v2\"\n",
    "    labeling_type = True\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(cfg.model_name,\n",
    "            bos_token=cfg.bos_token, eos_token=cfg.eos_token, unk_token=cfg.unk_token,\n",
    "            pad_token=cfg.pad_token, mask_token=cfg.mask_token, model_max_length = cfg.max_len)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a917505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료\n"
     ]
    }
   ],
   "source": [
    "path = './check_point/2023-02-01-08h-18m_epoch_5_sk_labeling_True.pth' # 말은 길게 하는데 내용이 애매함.\n",
    "model.load_state_dict(torch.load(path))\n",
    "print('완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "533ac793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user > 점심 먹었어?\n",
      "Chatbot >  오늘 점심엔 뭐 먹었\n",
      "user > 저녁은 뭐먹으려구\n",
      "Chatbot >  부대찌개가 맛있긴하지 ᄏ\n",
      "user > 운동 좋아해?\n",
      "Chatbot >  점심 뭐먹을지 고민중이야 ᄏ이따가 배고프면 나가서 사먹어야지 ᄏ\n",
      "user > 초기화\n",
      "user > 운동 좋아해?\n",
      "Chatbot >  뭐야\n",
      "user > 싫어?\n",
      "Chatbot >  왜? 헬스 같이 하자\n",
      "user > 좋아 어디 헬스장으로 갈까?\n",
      "Chatbot >  거긴 너무 멀어 \n",
      "user > 끝\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "대화 함수\n",
    "끝으로 대화 종료\n",
    "초기화로 이전 대화 초기화\n",
    "\n",
    "이전 대화가 history에 남아있음.\n",
    "\"\"\"\n",
    "\n",
    "history = \"\"\n",
    "start=True\n",
    "model.to(cfg.device)\n",
    "\n",
    "while True:\n",
    "    _input = input(\"user > \")\n",
    "    \n",
    "    if _input == \"끝\":\n",
    "        break\n",
    "    if _input == \"초기화\":\n",
    "        history = \"\"\n",
    "        continue\n",
    "    if start:\n",
    "        _input_word = cfg.bos_token + cfg.user_token + _input + cfg.bot_token\n",
    "        history += _input_word\n",
    "        start = False\n",
    "    else:\n",
    "        _input_word = cfg.user_token + _input + cfg.bot_token\n",
    "        history += _input_word\n",
    "        \n",
    "    input_ids = tokenizer.encode(history, return_tensors=\"pt\").to(cfg.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        gen_ids = model.generate(\n",
    "            input_ids,\n",
    "            top_k=3,\n",
    "            top_p=0.92,\n",
    "            num_beams=3,\n",
    "            do_samples=True,\n",
    "            max_length=1000,\n",
    "            no_repeat_ngram_size=3,\n",
    "            repetition_penalty=1.2,\n",
    "            temperature=0.9,\n",
    "            max_new_tokens=40,\n",
    "            eos_token_id= tokenizer.get_vocab()[cfg.eos_token],\n",
    "            bad_word_ids = [tokenizer.convert_tokens_to_ids(cfg.user_token), tokenizer.convert_tokens_to_ids('ㅋㅋ'), tokenizer.convert_tokens_to_ids('하하')]\n",
    "        )\n",
    "    \n",
    "    gen = tokenizer.decode(gen_ids[0])\n",
    "    try:\n",
    "        generated = gen[gen.rfind(\"<sys>\")+5:gen.index(\"</s>\")]\n",
    "    except:\n",
    "        generated = gen[gen.rfind(\"<sys>\")+5:]\n",
    "    history += generated\n",
    "    \n",
    "    #print(f'Chatbot > {gen}')\n",
    "    print(f'Chatbot > {generated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065d860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = '점심 먹었어?'\n",
    "input_word = cfg.bos_token + cfg.user_token + _input + cfg.bot_token\n",
    "input_ids = tokenizer.encode(input_word, return_tensors=\"pt\").to(cfg.device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d433afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<usr> 나심 뭐었어?  응'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(*torch.argmax(outputs.logits, dim=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
